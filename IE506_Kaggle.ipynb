{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "further-sister",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /home/23m1512/.local/lib/python3.9/site-packages (0.0)\r\n",
      "Requirement already satisfied: scikit-learn in /home/23m1512/.local/lib/python3.9/site-packages (from sklearn) (1.4.2)\r\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/lib/python3/dist-packages (from scikit-learn->sklearn) (1.19.5)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/23m1512/.local/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.4.0)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/lib/python3/dist-packages (from scikit-learn->sklearn) (1.6.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/23m1512/.local/lib/python3.9/site-packages (from scikit-learn->sklearn) (3.4.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "amino-title",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "direct-walter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47235\n",
      "[100, 200, 300, 400]\n",
      "[101, 102, 103, 104, 105, 109, 110, 115, 119, 120, 121, 122, 123, 127, 128, 130, 131, 133, 199, 235, 236, 238, 241, 245, 248, 252, 254, 258, 259, 299, 361, 399, 401, 494, 495, 496, 499]\n"
     ]
    }
   ],
   "source": [
    "max_id = 0\n",
    "main_class = []\n",
    "sub_class = []\n",
    "\n",
    "with open('IE506_2024_progchallenge_train.txt', 'r') as file:\n",
    "\n",
    "    for i,line in enumerate(file):\n",
    "        line_list = line.split(\" \")\n",
    "\n",
    "        M = line_list[0]\n",
    "        S = line_list[1]\n",
    "        F = line_list[2:].copy()\n",
    "        \n",
    "        # Extract numerical values using regular expressions\n",
    "        M = re.findall(r'\\d+', M)\n",
    "        S = re.findall(r'\\d+', S)\n",
    "\n",
    "        # Convert the extracted numbers to integers\n",
    "        main_class += [int(num) for num in M]\n",
    "        sub_class  += [int(num) for num in S]\n",
    "\n",
    "        for s in F:\n",
    "\n",
    "            id , val = s.split(':')\n",
    "\n",
    "            id = int(id)\n",
    "            val = float(val)\n",
    "\n",
    "            if max_id <= id:\n",
    "                max_id = id\n",
    "                 \n",
    "main_class.sort()\n",
    "sub_class.sort()\n",
    "\n",
    "print(max_id)\n",
    "print(sorted(set(main_class)))\n",
    "print(sorted(set(sub_class)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "departmental-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((200000, 47236))   # Feature matrix\n",
    "\n",
    "with open('IE506_2024_progchallenge_train.txt', 'r') as file:\n",
    "\n",
    "    for i,line in enumerate(file):\n",
    "\n",
    "        line_list = line.split(\" \")\n",
    "\n",
    "        F = line_list[2:].copy()\n",
    "\n",
    "        for s in F:\n",
    "\n",
    "            id , val = s.split(':')\n",
    "\n",
    "            id = int(id)\n",
    "            val = float(val)\n",
    "\n",
    "            X[i, id] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "approximate-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options to show all rows and columns\n",
    "# pd.set_option(\"display.max_rows\", None)\n",
    "# pd.set_option(\"display.max_columns\", None)\n",
    "# df = pd.DataFrame(F_matrix[:10, :])\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "rolled-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_matrix = []\n",
    "\n",
    "main_class = [100, 200, 300, 400]\n",
    "sub_class = [101, 102, 103, 104, 105, 109, 110, 115, 119, 120, 121, 122, 123, 127, 128, 130, 131, 133, 199, 235, 236, 238, 241, 245, 248, 252, 254, 258, 259, 299, 361, 399, 401, 494, 495, 496, 499]\n",
    "\n",
    "with open('IE506_2024_progchallenge_train.txt', 'r') as file:\n",
    "\n",
    "    for i,line in enumerate(file):\n",
    "        line_list = line.split(\" \")\n",
    "\n",
    "        M = line_list[0]\n",
    "        S = line_list[1]\n",
    "\n",
    "        # Extract numerical values using regular expressions\n",
    "        M = re.findall(r'\\d+', M)\n",
    "        S = re.findall(r'\\d+', S)\n",
    "\n",
    "        # Convert the extracted numbers to integers\n",
    "        M = [int(num) for num in M]\n",
    "        S  = [int(num) for num in S]\n",
    "\n",
    "        main_class_vec = [1 if label in M else 0 for label in main_class]\n",
    "        sub_class_vec = [1 if label in S else 0 for label in sub_class]\n",
    "\n",
    "        # Concatenate main class and subclass vectors\n",
    "        class_vector = main_class_vec + sub_class_vec\n",
    "       \n",
    "        # Append the class vector to the class matrix\n",
    "        class_matrix.append(class_vector)\n",
    "\n",
    "        \n",
    "y = np.array(class_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "metallic-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options to show all rows and columns\n",
    "# pd.set_option(\"display.max_rows\", None)\n",
    "# pd.set_option(\"display.max_columns\", None)\n",
    " \n",
    "df1 = pd.DataFrame(y)\n",
    "df1.columns = [100, 200, 300, 400, 101, 102, 103, 104, 105, 109, 110, 115, 119, 120, 121, 122, 123, 127, 128, 130, 131, 133, 199, 235, 236, 238, 241, 245, 248, 252, 254, 258, 259, 299, 361, 399, 401, 494, 495, 496, 499]\n",
    "#df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75720767-ac42-43f4-a105-5445f7551e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle indices\n",
    "# indices = np.arange(len(X))\n",
    "# np.random.seed(42)\n",
    "# np.random.shuffle(indices)\n",
    "# indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86ecf4be-8eb8-455e-81c1-33df8a33753b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /home/23m1512/.local/lib/python3.9/site-packages (1.4.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-cylinder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "indices_all = np.arange(len(X))\n",
    "lambda_j=[]\n",
    "\n",
    "for i in range(41):\n",
    "    bootstrap_indices = np.random.choice(indices_all, size=10000)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[bootstrap_indices], y[bootstrap_indices][:,i], test_size=0.2, random_state=42)\n",
    "    # Define the parameter grid\n",
    "    param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "    # Initialize Logistic Regression model with L1 penalty and liblinear solver\n",
    "    logistic_regression = LogisticRegression(penalty='l1', solver='liblinear', max_iter=1000)\n",
    "\n",
    "    # Initialize GridSearchCV\n",
    "    grid_search = GridSearchCV(estimator=logistic_regression, param_grid=param_grid, cv=5)\n",
    "\n",
    "    # Train the model and find best parameters\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Best parameters found\n",
    "    best_params = grid_search.best_params_\n",
    "    print(\"Best C value:\", best_params['C'])\n",
    "    lambda_j.append(best_params['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "temporal-significance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10,\n",
       " 10,\n",
       " 10,\n",
       " 100,\n",
       " 1,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 100,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 0.001,\n",
       " 1,\n",
       " 10,\n",
       " 10,\n",
       " 100,\n",
       " 10,\n",
       " 10,\n",
       " 100,\n",
       " 10,\n",
       " 100,\n",
       " 100,\n",
       " 0.001,\n",
       " 100,\n",
       " 10,\n",
       " 0.001,\n",
       " 10,\n",
       " 100,\n",
       " 10,\n",
       " 100]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [10,10,10,100,1,10,10,10,10,10,10,100,10,10,10,10,10,100,100,100,100,100,0.001,1,10,10,100,10,10,100,10,100,100,0.001,100,10,0.001,10,100,10,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb9f2bf-168a-403b-8cc1-ca5770b9c384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 20\n",
      "8 21\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "model_matrix=np.array([['model1_1', 'model1_2', 'model1_3', 'model1_4', 'model1_5', 'model1_6', 'model1_7', 'model1_8', 'model1_9', 'model1_10', 'model1_11', 'model1_12', 'model1_13', 'model1_14', 'model1_15', 'model1_16', 'model1_17', 'model1_18', 'model1_19', 'model1_20', 'model1_21', 'model1_22', 'model1_23', 'model1_24', 'model1_25', 'model1_26', 'model1_27', 'model1_28', 'model1_29', 'model1_30', 'model1_31', 'model1_32', 'model1_33', 'model1_34', 'model1_35', 'model1_36', 'model1_37', 'model1_38', 'model1_39', 'model1_40', 'model1_41'],\n",
    "['model2_1', 'model2_2', 'model2_3', 'model2_4', 'model2_5', 'model2_6', 'model2_7', 'model2_8', 'model2_9', 'model2_10', 'model2_11', 'model2_12', 'model2_13', 'model2_14', 'model2_15', 'model2_16', 'model2_17', 'model2_18', 'model2_19', 'model2_20', 'model2_21', 'model2_22', 'model2_23', 'model2_24', 'model2_25', 'model2_26', 'model2_27', 'model2_28', 'model2_29', 'model2_30', 'model2_31', 'model2_32', 'model2_33', 'model2_34', 'model2_35', 'model2_36', 'model2_37', 'model2_38', 'model2_39', 'model2_40', 'model2_41'],\n",
    "['model3_1', 'model3_2', 'model3_3', 'model3_4', 'model3_5', 'model3_6', 'model3_7', 'model3_8', 'model3_9', 'model3_10', 'model3_11', 'model3_12', 'model3_13', 'model3_14', 'model3_15', 'model3_16', 'model3_17', 'model3_18', 'model3_19', 'model3_20', 'model3_21', 'model3_22', 'model3_23', 'model3_24', 'model3_25', 'model3_26', 'model3_27', 'model3_28', 'model3_29', 'model3_30', 'model3_31', 'model3_32', 'model3_33', 'model3_34', 'model3_35', 'model3_36', 'model3_37', 'model3_38', 'model3_39', 'model3_40', 'model3_41'],\n",
    "['model4_1', 'model4_2', 'model4_3', 'model4_4', 'model4_5', 'model4_6', 'model4_7', 'model4_8', 'model4_9', 'model4_10', 'model4_11', 'model4_12', 'model4_13', 'model4_14', 'model4_15', 'model4_16', 'model4_17', 'model4_18', 'model4_19', 'model4_20', 'model4_21', 'model4_22', 'model4_23', 'model4_24', 'model4_25', 'model4_26', 'model4_27', 'model4_28', 'model4_29', 'model4_30', 'model4_31', 'model4_32', 'model4_33', 'model4_34', 'model4_35', 'model4_36', 'model4_37', 'model4_38', 'model4_39', 'model4_40', 'model4_41'],\n",
    "['model5_1', 'model5_2', 'model5_3', 'model5_4', 'model5_5', 'model5_6', 'model5_7', 'model5_8', 'model5_9', 'model5_10', 'model5_11', 'model5_12', 'model5_13', 'model5_14', 'model5_15', 'model5_16', 'model5_17', 'model5_18', 'model5_19', 'model5_20', 'model5_21', 'model5_22', 'model5_23', 'model5_24', 'model5_25', 'model5_26', 'model5_27', 'model5_28', 'model5_29', 'model5_30', 'model5_31', 'model5_32', 'model5_33', 'model5_34', 'model5_35', 'model5_36', 'model5_37', 'model5_38', 'model5_39', 'model5_40', 'model5_41'],\n",
    "['model6_1', 'model6_2', 'model6_3', 'model6_4', 'model6_5', 'model6_6', 'model6_7', 'model6_8', 'model6_9', 'model6_10', 'model6_11', 'model6_12', 'model6_13', 'model6_14', 'model6_15', 'model6_16', 'model6_17', 'model6_18', 'model6_19', 'model6_20', 'model6_21', 'model6_22', 'model6_23', 'model6_24', 'model6_25', 'model6_26', 'model6_27', 'model6_28', 'model6_29', 'model6_30', 'model6_31', 'model6_32', 'model6_33', 'model6_34', 'model6_35', 'model6_36', 'model6_37', 'model6_38', 'model6_39', 'model6_40', 'model6_41'],\n",
    "['model7_1', 'model7_2', 'model7_3', 'model7_4', 'model7_5', 'model7_6', 'model7_7', 'model7_8', 'model7_9', 'model7_10', 'model7_11', 'model7_12', 'model7_13', 'model7_14', 'model7_15', 'model7_16', 'model7_17', 'model7_18', 'model7_19', 'model7_20', 'model7_21', 'model7_22', 'model7_23', 'model7_24', 'model7_25', 'model7_26', 'model7_27', 'model7_28', 'model7_29', 'model7_30', 'model7_31', 'model7_32', 'model7_33', 'model7_34', 'model7_35', 'model7_36', 'model7_37', 'model7_38', 'model7_39', 'model7_40', 'model7_41'],\n",
    "['model8_1', 'model8_2', 'model8_3', 'model8_4', 'model8_5', 'model8_6', 'model8_7', 'model8_8', 'model8_9', 'model8_10', 'model8_11', 'model8_12', 'model8_13', 'model8_14', 'model8_15', 'model8_16', 'model8_17', 'model8_18', 'model8_19', 'model8_20', 'model8_21', 'model8_22', 'model8_23', 'model8_24', 'model8_25', 'model8_26', 'model8_27', 'model8_28', 'model8_29', 'model8_30', 'model8_31', 'model8_32', 'model8_33', 'model8_34', 'model8_35', 'model8_36', 'model8_37', 'model8_38', 'model8_39', 'model8_40', 'model8_41'],\n",
    "['model9_1', 'model9_2', 'model9_3', 'model9_4', 'model9_5', 'model9_6', 'model9_7', 'model9_8', 'model9_9', 'model9_10', 'model9_11', 'model9_12', 'model9_13', 'model9_14', 'model9_15', 'model9_16', 'model9_17', 'model9_18', 'model9_19', 'model9_20', 'model9_21', 'model9_22', 'model9_23', 'model9_24', 'model9_25', 'model9_26', 'model9_27', 'model9_28', 'model9_29', 'model9_30', 'model9_31', 'model9_32', 'model9_33', 'model9_34', 'model9_35', 'model9_36', 'model9_37', 'model9_38', 'model9_39', 'model9_40', 'model9_41'],\n",
    "['model10_1', 'model10_2', 'model10_3', 'model10_4', 'model10_5', 'model10_6', 'model10_7', 'model10_8', 'model10_9', 'model10_10', 'model10_11', 'model10_12', 'model10_13', 'model10_14', 'model10_15', 'model10_16', 'model10_17', 'model10_18', 'model10_19', 'model10_20', 'model10_21', 'model10_22', 'model10_23', 'model10_24', 'model10_25', 'model10_26', 'model10_27', 'model10_28', 'model10_29', 'model10_30', 'model10_31', 'model10_32', 'model10_33', 'model10_34', 'model10_35', 'model10_36', 'model10_37', 'model10_38', 'model10_39', 'model10_40', 'model10_41'],\n",
    "['model11_1', 'model11_2', 'model11_3', 'model11_4', 'model11_5', 'model11_6', 'model11_7', 'model11_8', 'model11_9', 'model11_10', 'model11_11', 'model11_12', 'model11_13', 'model11_14', 'model11_15', 'model11_16', 'model11_17', 'model11_18', 'model11_19', 'model11_20', 'model11_21', 'model11_22', 'model11_23', 'model11_24', 'model11_25', 'model11_26', 'model11_27', 'model11_28', 'model11_29', 'model11_30', 'model11_31', 'model11_32', 'model11_33', 'model11_34', 'model11_35', 'model11_36', 'model11_37', 'model11_38', 'model11_39', 'model11_40', 'model11_41'],\n",
    "['model12_1', 'model12_2', 'model12_3', 'model12_4', 'model12_5', 'model12_6', 'model12_7', 'model12_8', 'model12_9', 'model12_10', 'model12_11', 'model12_12', 'model12_13', 'model12_14', 'model12_15', 'model12_16', 'model12_17', 'model12_18', 'model12_19', 'model12_20', 'model12_21', 'model12_22', 'model12_23', 'model12_24', 'model12_25', 'model12_26', 'model12_27', 'model12_28', 'model12_29', 'model12_30', 'model12_31', 'model12_32', 'model12_33', 'model12_34', 'model12_35', 'model12_36', 'model12_37', 'model12_38', 'model12_39', 'model12_40', 'model12_41'],\n",
    "['model13_1', 'model13_2', 'model13_3', 'model13_4', 'model13_5', 'model13_6', 'model13_7', 'model13_8', 'model13_9', 'model13_10', 'model13_11', 'model13_12', 'model13_13', 'model13_14', 'model13_15', 'model13_16', 'model13_17', 'model13_18', 'model13_19', 'model13_20', 'model13_21', 'model13_22', 'model13_23', 'model13_24', 'model13_25', 'model13_26', 'model13_27', 'model13_28', 'model13_29', 'model13_30', 'model13_31', 'model13_32', 'model13_33', 'model13_34', 'model13_35', 'model13_36', 'model13_37', 'model13_38', 'model13_39', 'model13_40', 'model13_41'],\n",
    "['model14_1', 'model14_2', 'model14_3', 'model14_4', 'model14_5', 'model14_6', 'model14_7', 'model14_8', 'model14_9', 'model14_10', 'model14_11', 'model14_12', 'model14_13', 'model14_14', 'model14_15', 'model14_16', 'model14_17', 'model14_18', 'model14_19', 'model14_20', 'model14_21', 'model14_22', 'model14_23', 'model14_24', 'model14_25', 'model14_26', 'model14_27', 'model14_28', 'model14_29', 'model14_30', 'model14_31', 'model14_32', 'model14_33', 'model14_34', 'model14_35', 'model14_36', 'model14_37', 'model14_38', 'model14_39', 'model14_40', 'model14_41'],\n",
    "['model15_1', 'model15_2', 'model15_3', 'model15_4', 'model15_5', 'model15_6', 'model15_7', 'model15_8', 'model15_9', 'model15_10', 'model15_11', 'model15_12', 'model15_13', 'model15_14', 'model15_15', 'model15_16', 'model15_17', 'model15_18', 'model15_19', 'model15_20', 'model15_21', 'model15_22', 'model15_23', 'model15_24', 'model15_25', 'model15_26', 'model15_27', 'model15_28', 'model15_29', 'model15_30', 'model15_31', 'model15_32', 'model15_33', 'model15_34', 'model15_35', 'model15_36', 'model15_37', 'model15_38', 'model15_39', 'model15_40', 'model15_41'],\n",
    "['model16_1', 'model16_2', 'model16_3', 'model16_4', 'model16_5', 'model16_6', 'model16_7', 'model16_8', 'model16_9', 'model16_10', 'model16_11', 'model16_12', 'model16_13', 'model16_14', 'model16_15', 'model16_16', 'model16_17', 'model16_18', 'model16_19', 'model16_20', 'model16_21', 'model16_22', 'model16_23', 'model16_24', 'model16_25', 'model16_26', 'model16_27', 'model16_28', 'model16_29', 'model16_30', 'model16_31', 'model16_32', 'model16_33', 'model16_34', 'model16_35', 'model16_36', 'model16_37', 'model16_38', 'model16_39', 'model16_40', 'model16_41'],\n",
    "['model17_1', 'model17_2', 'model17_3', 'model17_4', 'model17_5', 'model17_6', 'model17_7', 'model17_8', 'model17_9', 'model17_10', 'model17_11', 'model17_12', 'model17_13', 'model17_14', 'model17_15', 'model17_16', 'model17_17', 'model17_18', 'model17_19', 'model17_20', 'model17_21', 'model17_22', 'model17_23', 'model17_24', 'model17_25', 'model17_26', 'model17_27', 'model17_28', 'model17_29', 'model17_30', 'model17_31', 'model17_32', 'model17_33', 'model17_34', 'model17_35', 'model17_36', 'model17_37', 'model17_38', 'model17_39', 'model17_40', 'model17_41'],\n",
    "['model18_1', 'model18_2', 'model18_3', 'model18_4', 'model18_5', 'model18_6', 'model18_7', 'model18_8', 'model18_9', 'model18_10', 'model18_11', 'model18_12', 'model18_13', 'model18_14', 'model18_15', 'model18_16', 'model18_17', 'model18_18', 'model18_19', 'model18_20', 'model18_21', 'model18_22', 'model18_23', 'model18_24', 'model18_25', 'model18_26', 'model18_27', 'model18_28', 'model18_29', 'model18_30', 'model18_31', 'model18_32', 'model18_33', 'model18_34', 'model18_35', 'model18_36', 'model18_37', 'model18_38', 'model18_39', 'model18_40', 'model18_41'],\n",
    "['model19_1', 'model19_2', 'model19_3', 'model19_4', 'model19_5', 'model19_6', 'model19_7', 'model19_8', 'model19_9', 'model19_10', 'model19_11', 'model19_12', 'model19_13', 'model19_14', 'model19_15', 'model19_16', 'model19_17', 'model19_18', 'model19_19', 'model19_20', 'model19_21', 'model19_22', 'model19_23', 'model19_24', 'model19_25', 'model19_26', 'model19_27', 'model19_28', 'model19_29', 'model19_30', 'model19_31', 'model19_32', 'model19_33', 'model19_34', 'model19_35', 'model19_36', 'model19_37', 'model19_38', 'model19_39', 'model19_40', 'model19_41'],\n",
    "['model20_1', 'model20_2', 'model20_3', 'model20_4', 'model20_5', 'model20_6', 'model20_7', 'model20_8', 'model20_9', 'model20_10', 'model20_11', 'model20_12', 'model20_13', 'model20_14', 'model20_15', 'model20_16', 'model20_17', 'model20_18', 'model20_19', 'model20_20', 'model20_21', 'model20_22', 'model20_23', 'model20_24', 'model20_25', 'model20_26', 'model20_27', 'model20_28', 'model20_29', 'model20_30', 'model20_31', 'model20_32', 'model20_33', 'model20_34', 'model20_35', 'model20_36', 'model20_37', 'model20_38', 'model20_39', 'model20_40', 'model20_41']])\n",
    "\n",
    "accuracy_matrix=np.zeros((20,41))\n",
    "indices_all = np.arange(len(X))\n",
    "lambda_j=[10,10,10,100,1,10,10,10,10,10,10,100,10,10,10,10,10,100,100,100,100,100,0.001,1,10,10,100,10,10,100,10,100,100,0.001,100,10,0.001,10,100,10,100]\n",
    "\n",
    "for j in range(1,21):\n",
    "#     if j==7:\n",
    "#         z=36\n",
    "#     else:\n",
    "#         z=0\n",
    "\n",
    "    bootstrap_indices = np.random.choice(indices_all, size=40000, replace=True)\n",
    "\n",
    "    for i in range(41):\n",
    "        # Split the dataset into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X[bootstrap_indices], y[bootstrap_indices][:,i], test_size=0.2, random_state=42)\n",
    "\n",
    "        if len(np.unique(y_train))==1:\n",
    "            model_matrix[j-1, i] = np.unique(y_train)[0]\n",
    "            print(\"Accuracy of model\",i+1,': _' )\n",
    "            accuracy_matrix[j-1,i]= '_'\n",
    "            continue\n",
    "\n",
    "        # Initialize Logistic Regression model\n",
    "        model = LogisticRegression(penalty='l1', solver='liblinear', C= lambda_j[i], max_iter=1000)\n",
    "\n",
    "        # Train the model and find the best parameters\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Evaluate the best model\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        globals()[model_matrix[j-1,i]]=clone(model)\n",
    "\n",
    "        joblib.dump(model, model_matrix[j-1,i]+'.pkl')\n",
    "\n",
    "        # Accuracy calculation\n",
    "        accuracy_matrix[j-1,i]=accuracy\n",
    "        print(j-1,i)\n",
    "        # print(\"Accuracy of model\",i+1,':', accuracy)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c0324c-6793-4c4a-a53a-478932ae7b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d473fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63de549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading test data\n",
    "\n",
    "max_id = 0\n",
    "i = 0\n",
    "\n",
    "with open('IE506_2024_progchallenge_test.txt', 'r') as file:\n",
    "\n",
    "    for i,line in enumerate(file):\n",
    "        i += 1\n",
    "        line_list = line.split(\" \")\n",
    "\n",
    "        for s in line_list:\n",
    "            id , val = s.split(':')\n",
    "            id = int(id)\n",
    "            val = float(val)\n",
    "\n",
    "            if max_id <= id:\n",
    "                max_id = id\n",
    "print(max_id)\n",
    "print(i)\n",
    "\n",
    "X_test = np.zeros((150000, 47236))   # Feature matrix\n",
    "\n",
    "\n",
    "with open('IE506_2024_progchallenge_test.txt', 'r') as file:\n",
    "    for i,line in enumerate(file):\n",
    "        line_list = line.split(\" \")\n",
    "        for s in line_list:\n",
    "            id , val = s.split(':')\n",
    "            id = int(id)\n",
    "            val = float(val)\n",
    "            X_test[i, id] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fa6fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading pickels\n",
    "import joblib\n",
    "import os\n",
    "for i in range(20):\n",
    "    for j in range(41):\n",
    "        if os.path.isfile(model_matrix[i,j]+'.pkl'):\n",
    "            globals()[model_matrix[i,j]]=joblib.load(model_matrix[i,j]+'.pkl')\n",
    "        else:\n",
    "            print('blank spotted')\n",
    "            model_matrix[i,j]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ec4d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_matrix=np.array([['y_pred1_1','y_pred2_1','y_pred3_1','y_pred4_1','y_pred5_1','y_pred6_1','y_pred7_1','y_pred8_1','y_pred9_1','y_pred10_1','y_pred11_1','y_pred12_1','y_pred13_1','y_pred14_1','y_pred15_1','y_pred16_1','y_pred17_1','y_pred18_1','y_pred19_1','y_pred20_1']\n",
    "pred_matrix=[]\n",
    "for i in range(20):\n",
    "    L=[]\n",
    "    for j in range(41):\n",
    "        if model_matrix[i,j]!=0 and model_matrix[i,j]!=1:\n",
    "            L.append(globals()[model_matrix[i,j]].predict(X_test))\n",
    "        else:\n",
    "            if model_matrix[i,j]==0:\n",
    "                L.append(np.zeros((X_test.shape[0],1)))\n",
    "            else:\n",
    "                L.append(np.ones((X_test.shape[0],1)))\n",
    "    print(i,j)\n",
    "    pred_matrix.append(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebb9686",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted =np.zeros((X_test.shape[0],41))\n",
    "\n",
    "for k in range(X_test.shape[0]):\n",
    "    for j in range(41):\n",
    "        L1=[]\n",
    "        for i in range(20):\n",
    "            L1.append(pred_matrix[i][j][k])\n",
    "        if L1.count(1)>L1.count(0):\n",
    "            y_predicted[k,j]=1\n",
    "        elif L1.count(1)<L1.count(0):\n",
    "            y_predicted[k,j]=0\n",
    "        else:\n",
    "            y_predicted[k,j]=np.random.choice([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affb0978",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3b715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_list=[]\n",
    "S_list=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    M_labels=['100','200','300','400']\n",
    "    L2=[]\n",
    "    for j in range(4):\n",
    "        if y_predicted[i,j]==1:\n",
    "            L2.append(M_labels[j])\n",
    "    M_list.append(L2)\n",
    "    \n",
    "    S_labels=['101', '102', '103', '104', '105', '109', '110', '115', '119', '120', '121', '122', '123', '127', '128', '130', '131', '133', '199', '235', '236', '238', '241', '245', '248', '252', '254', '258', '259', '299', '361', '399', '401', '494', '495', '496', '499']\n",
    "    L3=[]\n",
    "    for j in range(4,41):\n",
    "        if y_predicted[i,j]==1:\n",
    "            L3.append(S_labels[j-4])\n",
    "    S_list.append(L3)\n",
    "\n",
    "df=pd.DataFrame({'ID':list(np.arange(0,X_test.shape[0])), 'M':M_list, 'S':S_list})\n",
    " \n",
    "# Create the DataFrame\n",
    "joblib.dump(df, 'predicted_labels.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b198067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory to store the CSV files\n",
    "directory = \"prediction\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "filename = os.path.join(directory, f\"predicted_labels.csv\")\n",
    "df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f10678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
